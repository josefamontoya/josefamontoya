{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de TMY – versión notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando archivo: /home/josefa_montoya/Josefamontoya/josefamontoya/PRUEBA_2/Vallenar_corrupted.csv\n",
      "\n",
      "Archivo procesado y guardado como: /home/josefa_montoya/Josefamontoya/josefamontoya/PRUEBA_2/Vallenar_processed.csv\n",
      "Reporte de calidad guardado como: /home/josefa_montoya/Josefamontoya/josefamontoya/PRUEBA_2/Vallenar_processed_report.txt\n",
      "\n",
      "Procesando archivo: /home/josefa_montoya/Josefamontoya/josefamontoya/PRUEBA_2/calama_corrupted.csv\n",
      "\n",
      "Archivo procesado y guardado como: /home/josefa_montoya/Josefamontoya/josefamontoya/PRUEBA_2/calama_processed.csv\n",
      "Reporte de calidad guardado como: /home/josefa_montoya/Josefamontoya/josefamontoya/PRUEBA_2/calama_processed_report.txt\n",
      "\n",
      "Procesando archivo: /home/josefa_montoya/Josefamontoya/josefamontoya/PRUEBA_2/salvador_corrupted.csv\n",
      "\n",
      "Archivo procesado y guardado como: /home/josefa_montoya/Josefamontoya/josefamontoya/PRUEBA_2/salvador_processed.csv\n",
      "Reporte de calidad guardado como: /home/josefa_montoya/Josefamontoya/josefamontoya/PRUEBA_2/salvador_processed_report.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "def smooth_data(data, window_size=5):\n",
    "    \"\"\"\n",
    "    Aplica un filtro de media móvil a los datos.\n",
    "    \n",
    "    Args:\n",
    "        data (array): Datos a suavizar\n",
    "        window_size (int): Tamaño de la ventana para el suavizado\n",
    "    \n",
    "    Returns:\n",
    "        array: Datos suavizados\n",
    "    \"\"\"\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "def process_tmy_file(input_file, output_file, target_year=2014):\n",
    "    \"\"\"\n",
    "    Procesa un archivo TMY y genera un reporte de calidad.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Ruta del archivo de entrada\n",
    "        output_file (str): Ruta del archivo de salida\n",
    "        target_year (int): Año al que se ajustarán todas las fechas\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcesando archivo: {input_file}\")\n",
    "    \n",
    "    # Leer los datos principales\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Reporte de calidad inicial\n",
    "    calidad_inicial = []\n",
    "    calidad_inicial.append(f\"Archivo procesado: {input_file}\\n\")\n",
    "    calidad_inicial.append(f\"Total de registros: {len(df)}\\n\")\n",
    "    calidad_inicial.append(\"Valores nulos por columna (antes de limpieza):\\n\")\n",
    "    calidad_inicial.append(str(df.isnull().sum()))\n",
    "    calidad_inicial.append(\"\\nEstadísticas descriptivas (antes de limpieza):\\n\")\n",
    "    calidad_inicial.append(str(df.describe()))\n",
    "    \n",
    "    # Guardar copia para comparar después\n",
    "    df_limpio = df.copy()\n",
    "    \n",
    "    # Cambiar el año a 2014\n",
    "    df_limpio['Year'] = target_year\n",
    "    \n",
    "    # Verificar y corregir datos\n",
    "    df_limpio['GHI'] = pd.to_numeric(df_limpio['GHI'], errors='coerce').clip(lower=0, upper=1200)\n",
    "    df_limpio['DNI'] = pd.to_numeric(df_limpio['DNI'], errors='coerce').clip(lower=0, upper=1200)\n",
    "    df_limpio['DHI'] = pd.to_numeric(df_limpio['DHI'], errors='coerce').clip(lower=0, upper=400)\n",
    "    df_limpio['Tdry'] = pd.to_numeric(df_limpio['Tdry'], errors='coerce').clip(lower=-20, upper=50)\n",
    "    df_limpio['Tdew'] = pd.to_numeric(df_limpio['Tdew'], errors='coerce').clip(lower=-25, upper=30)\n",
    "    df_limpio['RH'] = pd.to_numeric(df_limpio['RH'], errors='coerce').clip(lower=0, upper=100)\n",
    "    df_limpio['Pres'] = pd.to_numeric(df_limpio['Pres'], errors='coerce').clip(lower=850, upper=1100)\n",
    "    df_limpio['Wspd'] = pd.to_numeric(df_limpio['Wspd'], errors='coerce').clip(lower=0, upper=100)\n",
    "    df_limpio['Wdir'] = pd.to_numeric(df_limpio['Wdir'], errors='coerce').clip(lower=0, upper=360)\n",
    "    df_limpio['Snow Depth'] = pd.to_numeric(df_limpio['Snow Depth'], errors='coerce').clip(lower=0, upper=500)\n",
    "    \n",
    "    # Aplicar suavizado a los datos\n",
    "    df_limpio['GHI'] = smooth_data(df_limpio['GHI'].values)\n",
    "    df_limpio['DNI'] = smooth_data(df_limpio['DNI'].values)\n",
    "    df_limpio['DHI'] = smooth_data(df_limpio['DHI'].values)\n",
    "    \n",
    "    # Rellenar valores nulos mediante interpolación\n",
    "    df_limpio = df_limpio.interpolate(method='linear')\n",
    "    \n",
    "    # Reporte de calidad final\n",
    "    calidad_final = []\n",
    "    calidad_final.append(\"\\nValores nulos por columna (después de limpieza):\\n\")\n",
    "    calidad_final.append(str(df_limpio.isnull().sum()))\n",
    "    calidad_final.append(\"\\nEstadísticas descriptivas (después de limpieza):\\n\")\n",
    "    calidad_final.append(str(df_limpio.describe()))\n",
    "    \n",
    "    # Resumen de correcciones\n",
    "    resumen = []\n",
    "    resumen.append(\"\\nResumen de correcciones:\")\n",
    "    resumen.append(\"-\" * 50)\n",
    "    resumen.append(\"GHI, DNI, DHI: Valores negativos convertidos a 0, límites aplicados\")\n",
    "    resumen.append(\"Tdry: Limitada entre -20°C y 50°C\")\n",
    "    resumen.append(\"Tdew: Limitada entre -25°C y 30°C\")\n",
    "    resumen.append(\"RH: Limitada entre 0% y 100%\")\n",
    "    resumen.append(\"Pres: Limitada entre 850 y 1100 hPa\")\n",
    "    resumen.append(\"Wspd: Limitada entre 0 y 100 m/s\")\n",
    "    resumen.append(\"Wdir: Limitada entre 0° y 360°\")\n",
    "    resumen.append(\"Snow Depth: Limitada entre 0 y 500\")\n",
    "    for col in ['GHI', 'DNI', 'DHI', 'Tdry', 'Tdew', 'RH', 'Pres', 'Wspd', 'Wdir', 'Snow Depth']:\n",
    "        if col in df.columns:\n",
    "            original_nulls = df[col].isnull().sum()\n",
    "            final_nulls = df_limpio[col].isnull().sum()\n",
    "            resumen.append(f\"{col}: {original_nulls} nulos antes, {final_nulls} nulos después\")\n",
    "    \n",
    "    # Guardar el archivo limpio\n",
    "    df_limpio.to_csv(output_file, index=False)\n",
    "    print(f\"\\nArchivo procesado y guardado como: {output_file}\")\n",
    "    \n",
    "    # Guardar el reporte de calidad\n",
    "    report_file = output_file.replace('.csv', '_report.txt')\n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write('\\n'.join(calidad_inicial))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n'.join(resumen))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n'.join(calidad_final))\n",
    "    print(f\"Reporte de calidad guardado como: {report_file}\")\n",
    "\n",
    "def main():\n",
    "    # Directorio base\n",
    "    base_dir = '/home/josefa_montoya/Josefamontoya/josefamontoya/PRUEBA_2'\n",
    "    \n",
    "    # Lista de archivos a procesar\n",
    "    files_to_process = [\n",
    "        'Vallenar_corrupted.csv',\n",
    "        'calama_corrupted.csv',\n",
    "        'salvador_corrupted.csv'\n",
    "    ]\n",
    "    \n",
    "    # Procesar cada archivo\n",
    "    for file_name in files_to_process:\n",
    "        input_path = os.path.join(base_dir, file_name)\n",
    "        output_path = os.path.join(base_dir, file_name.replace('_corrupted.csv', '_processed.csv'))\n",
    "        process_tmy_file(input_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
